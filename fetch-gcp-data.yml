# .github/workflows/fetch-gcp-data.yml
# 
# Fetches GCP (Global Consciousness Project) data every 10 minutes,
# processes it into JSON, and commits to the repo so GitHub Pages can serve it.
#
# GitHub Actions free tier: 2,000 min/month
# This uses ~720 min/month (6 runs/hr × 24hr × 30 days × ~10sec each)

name: Fetch GCP Data

on:
  schedule:
    # Every 10 minutes
    - cron: '*/10 * * * *'
  workflow_dispatch:  # Allow manual trigger

permissions:
  contents: write

jobs:
  fetch-data:
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Fetch GCP data
        run: python fetch_gcp_data.py

      - name: Commit and push if data changed
        run: |
          git config user.name "GCP Data Bot"
          git config user.email "bot@gcpmonitor.com"
          git add data/
          
          # Only commit if there are actual changes
          if git diff --staged --quiet; then
            echo "No data changes, skipping commit"
          else
            git commit -m "Update GCP data $(date -u +%Y-%m-%dT%H:%M:%SZ)"
            git push
          fi
